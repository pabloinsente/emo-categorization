#
#
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/lmer_mean_diff_survey_dueling_bandits.r", echo=TRUE)
# grouped boxplot
ggplot(df2, aes(x = method, y = web.frequency)) +
geom_boxplot() +
geom_point()
stat.test <- df2  %>%
t_test(web.frequency ~ method, paired = TRUE) %>%
add_significance()
stat.test
df2$method
## format predictors
df2$method.dummy <- ifelse(df.forced$method == "survey", 1, 0)
## format predictors
df2$method.dummy <- ifelse(df2$method == "survey", 1, 0)
df2$method.center <- ifelse(df2$method == "survey", .5, -.5)
m1<-lmer(
web.frequency ~ 1 + method.dummy + (1 |photoID),
data = df2)
summary(m1)
Anova(m1, type = "III")
m2<-lmer(
web.frequency ~ 1 + method.center + (1 |photoID),
data = df2)
summary(m2)
df2$method.center
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
na.rm=FALSE, .drop=TRUE) {
library(plyr)
# Measure var on left, idvar + between vars on right of formula.
data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
.fun = function(xx, col, na.rm) {
c(subjMean = mean(xx[,col], na.rm=na.rm))
},
measurevar,
na.rm
)
# Put the subject means with original data
data <- merge(data, data.subjMean)
# Get the normalized data in a new column
measureNormedVar <- paste(measurevar, "_norm", sep="")
data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
mean(data[,measurevar], na.rm=na.rm)
# Remove this subject mean column
data$subjMean <- NULL
return(data)
}
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
# Ensure that the betweenvars and withinvars are factors
factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
FUN=is.factor, FUN.VALUE=logical(1))
if (!all(factorvars)) {
nonfactorvars <- names(factorvars)[!factorvars]
message("Automatically converting the following non-factors to factors: ",
paste(nonfactorvars, collapse = ", "))
data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
}
# Get the means from the un-normed data
datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Drop all the unused columns (these will be calculated with normed data)
datac$sd <- NULL
datac$se <- NULL
datac$ci <- NULL
# Norm each subject's data
ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
# This is the name of the new column
measurevar_n <- paste(measurevar, "_norm", sep="")
# Collapse the normed data - now we can treat between and within vars the same
ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Apply correction from Morey (2008) to the standard error and confidence interval
#  Get the product of the number of conditions of within-S variables
nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
FUN.VALUE=numeric(1)))
correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
# Apply the correction factor
ndatac$sd <- ndatac$sd * correctionFactor
ndatac$se <- ndatac$se * correctionFactor
ndatac$ci <- ndatac$ci * correctionFactor
# Combine the un-normed means with the normed results
merge(datac, ndatac)
}
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
method.table <- summarySEwithin(df2,
measurevar="web.frequency",
betweenvars=("method"),
idvar="photoID")
method.table
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
method.table <- summarySEwithin(df2,
measurevar="web.frequency",
betweenvars="method",
idvar="photoID")
method.table
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
method.table <- summarySEwithin(df2,
measurevar="web.frequency",
betweenvars=c("method"),
idvar="photoID")
method.table
df2
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/lmer_mean_diff_survey_dueling_bandits.r", echo=TRUE)
method.table
mean(df2$web.frequency)
sd(df2$web.frequency)
std.error(df2$web.frequency)
library(plotrix)
std.error(df2$web.frequency)
data_summary <- function(data, varname, groupnames){
require(plyr)
summary_func <- function(x, col){
c(mean = mean(x[[col]], na.rm=TRUE),
sd = sd(x[[col]], na.rm=TRUE))
}
data_sum<-ddply(data, groupnames, .fun=summary_func,
varname)
data_sum <- rename(data_sum, c("mean" = varname))
return(data_sum)
}
method.table <- data_summary(df2, varname="web.frequency",
groupnames=c("method"))
df3
method.table
data_summary <- function(data, varname, groupnames){
require(plyr)
summary_func <- function(x, col){
c(mean = mean(x[[col]], na.rm=TRUE),
sd = sd(x[[col]], na.rm=TRUE),
se = plotrix::std.error(x[[col]]))
}
data_sum<-ddply(data, groupnames, .fun=summary_func,
varname)
data_sum <- rename(data_sum, c("mean" = varname))
return(data_sum)
}
method.table <- data_summary(df2, varname="web.frequency",
groupnames=c("method"))
method.table
# # Mean + std error of the mean
ggplot(sex.ethnicity.sum.table, aes(x=method, y=web.frequency)) +
geom_errorbar(aes(ymin=web.frequency-se, ymax=web.frequency+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method")
# # Mean + std error of the mean
ggplot(method.table, aes(x=method, y=web.frequency)) +
geom_errorbar(aes(ymin=web.frequency-se, ymax=web.frequency+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method")
6e+06
# # Mean + std error of the mean
ggplot(method.table, aes(x=method, y=web.frequency, color=method)) +
geom_errorbar(aes(ymin=web.frequency-se, ymax=web.frequency+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method")
# # Mean + std error of the mean
ggplot(method.table, aes(x=method, y=web.frequency, color=method)) +
geom_errorbar(aes(ymin=web.frequency-se, ymax=web.frequency+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(fill="none")
# # Mean + std error of the mean
ggplot(method.table, aes(x=method, y=web.frequency, color=method)) +
geom_errorbar(aes(ymin=web.frequency-se, ymax=web.frequency+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(color="none")
# # Mean + std error of the mean
ggplot(method.table, aes(x=method, y=web.frequency, color=method)) +
geom_errorbar(aes(ymin=web.frequency-se, ymax=web.frequency+se), width=.3) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(color="none")
# # Mean + std error of the mean
ggplot(method.table, aes(x=method, y=web.frequency, color=method)) +
geom_errorbar(aes(ymin=web.frequency-se, ymax=web.frequency+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(color="none")
df2 %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_sd")
df2 %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = c("mean_sd", "mean_se"))
df2 %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_se")
method.table
method.table <- df2 %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_se")
method.table
names(method.table)
names(method.table)[4]
names(method.table)[4] <- "web-frequency mean"
names(method.table)[4] <- "web.frequency.mean"
# # Mean + std error of the mean
ggplot(method.table, aes(x=method, y=web.frequency.mean, color=method)) +
geom_errorbar(aes(ymin=web.frequency-se, ymax=web.frequency+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(color="none")
# # Mean + std error of the mean
ggplot(method.table, aes(x=method, y=web.frequency.mean, color=method)) +
geom_errorbar(aes(ymin=web.frequency.mean-se, ymax=web.frequency.mean+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(color="none")
# # Mean + std error of the mean
freq.survey <- ggplot(method.table, aes(x=method, y=web.frequency.mean, color=method)) +
geom_errorbar(aes(ymin=web.frequency.mean-se, ymax=web.frequency.mean+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(color="none")
s <- svgstring(width = 7,
height = 5)
library(svglite)
method.table <- df2 %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_se")
names(method.table)[4] <- "web.frequency.mean"
# # Mean + std error of the mean
freq.survey <- ggplot(method.table, aes(x=method, y=web.frequency.mean, color=method)) +
geom_errorbar(aes(ymin=web.frequency.mean-se, ymax=web.frequency.mean+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(color="none")
s <- svgstring(width = 7,
height = 5)
freq.survey
svg.string.plot <- s()
# # Mean + std error of the mean
freq.method <- ggplot(method.table, aes(x=method, y=web.frequency.mean, color=method)) +
geom_errorbar(aes(ymin=web.frequency.mean-se, ymax=web.frequency.mean+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(color="none")
s <- svgstring(width = 7,
height = 5)
freq.method
svg.string.plot <- s()
cat(svg.string.plot, file = "lmer_output/web_freq_method_uw_students.txt")
cat(svg.string.plot, file = "../../emotions_dashboard/data/web_freq_method_uw_students.txt")
dev.off()
ggsave('accuracy-charts/web_freq_method_uw_students.png', width = 8, height = 4)
summary(m1)
Anova(m1, type = "III")
# grouped boxplot
ggplot(df2, aes(x = method, y = web.frequency)) +
geom_boxplot() +
geom_point()
# grouped boxplot
ggplot(df2, aes(x = method, y = web.frequency, color=method)) +
geom_boxplot() +
geom_point() +
guides(color="none")
# grouped boxplot
boxplot <- ggplot(df2, aes(x = method, y = web.frequency, color=method)) +
geom_boxplot() +
geom_point() +
guides(color="none")
boxplot
s <- svgstring(width = 7,
height = 5)
boxplot
svg.string.plot <- s()
cat(svg.string.plot, file = "lmer_output/web_freq_method_boxplot_uw_students.txt")
cat(svg.string.plot, file = "../../emotions_dashboard/data/web_freq_method_boxplot_uw_students.txt")
dev.off()
ggsave('accuracy-charts/web_freq_method_boxplot_uw_students.png', width = 8, height = 4)
tab_model(m1)
library(sjPlot)
tab_model(m1)
anova_table<- Anova(m1, type = "III")
tab_model(anova_table)
anova_table
summary(m1)
tab_model(m1)
## odds ratio
tab_model(m1, file = "lmer_output/lmer_summary_method_ranking_uw_students.html")
tab_model(m1, file = "../../emotions_dashboard/data/lmer_summary_method_ranking_uw_students.html")
(aov <- anova(m1))
aov.apa <- kable(aov, digits = 3, format = "html", caption = "ANOVA table for LMER coefficients")
library(knitr)
aov.apa <- kable(aov, digits = 3, format = "html", caption = "ANOVA table for LMER coefficients")
aov <- anova(m1)
aov.apa <- kable(aov, digits = 3, format = "html", caption = "ANOVA table for LMER coefficients")
aov.apa
aov.apa <- kable(aov, digits = 3, format = "html", caption = "ANOVA table for LMER coefficients")
cat(aov.apa, file = "lmer_output/anova_lmer_method_ranking_free_uw_students.html")
cat(aov.apa, file = "../../emotions_dashboard/data/anova_lmer_method_ranking_free_uw_students.html")
### get mathematical formula
formula_lmer <- extract_eq(m1)
library(equatiomatic)
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/lmer_mean_diff_survey_dueling_bandits.r", echo=TRUE)
library(lmerTest)
library(ragg)
library(HLMdiag)
library(VCA)
df2$Model.F.Res<- residuals(m1) #extracts the residuals and places them in a new column in our original data table
df2$Abs.Model.F.Res <-abs(df2$Model.F.Res) #creates a new column with the absolute value of the residuals
df2$Model.F.Res2 <- df2$Abs.Model.F.Res^2 #squares the absolute values of the residuals to provide the more robust estimate
Levene.Model.F <- lm(Model.F.Res2 ~ participantId, data=df2) #ANOVA of the squared residuals
Levene.Model.F <- lm(Model.F.Res2 ~ photoID, data=df2) #ANOVA of the squared residuals
anova(Levene.Model.F) #displays the results
Plot.Model.F <- plot(m1) #creates a fitted vs residual plot
Plot.Model.F
require("lattice")
qqmath(m1, id=0.05) #id: identifies values that may be exerting undue influence on the model (i.e. outliers)
infl <- hlm_influence(m1, level = 1)
# IQR = as.numeric(format(IQR(infl$cooksd)*3, scientific = F))
CutOff = 4/nrow(infl)
print(CutOff)
dotplot_diag(infl$cooksd, name = "cooks.distance", cutoff = CutOff)
high_cooksd = infl[infl$cooksd > CutOff, ] %>%
arrange(desc(cooksd))
head(high_cooksd, n=10)
high_cooksd$id
##############
# images level
infl.classes <- hlm_influence(m1, level = "photoID")
CutOffGroup = 4/49
infl.classes
CutOffGroup = 4/19
CutOffGroup
dotplot_diag(infl.classes$cooksd, name = "cooks.distance", cutoff = "internal", modify = "dotplot")
dotplot_diag(infl$cooksd, name = "cooks.distance", cutoff = "internal")
dotplot_diag(infl$cooksd, name = "cooks.distance", cutoff = CutOff)
high_cooksd_participants = infl.classes[infl.classes$cooksd > CutOffGroup, ] %>%
arrange(desc(cooksd))
high_cooksd_participants
CutOffLeverage = mean(infl$leverage.overall)*3
CutOffLeverage
dotplot_diag(infl$leverage.overall, name = "leverage", cutoff = CutOffLeverage)
# head(high_leverage, n=10)
high_leverage
# high leverage data points
high_leverage$id
high_leverage = infl[infl$leverage.overall > CutOffLeverage, ] %>%
arrange(desc(leverage.overall))
# head(high_leverage, n=10)
high_leverage
# high leverage data points
high_leverage$id
CutOffLeverageParticipants = mean(infl.classes$leverage.overall)*3
CutOffLeverageParticipants
dotplot_diag(infl.classes$leverage.overall, name = "leverage", cutoff = CutOffLeverageParticipants)
high_cooksd$id
nrow(df)
#add index column to data frame
df2$id <- 1:nrow(df2)
`%ni%` <- Negate(`%in%`)
df.filtered <- filter(df, id %ni% high_cooksd$id)
df.filtered
df.filtered <- filter(df2, id %ni% high_cooksd$id)
nrow(df2)
nrow(df2)
nrow(df.filtered)
m3<-lmer(
web.frequency ~ 1 + method.dummy + (1 |photoID),
data = df.filtered)
summary(m3)
tab_model(m1)
df.filtered %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_se")
# grouped boxplot
boxplot <- ggplot(df.filtered, aes(x = method, y = web.frequency, color=method)) +
geom_boxplot() +
geom_point() +
guides(color="none")
boxplot
summary(m3)
Anova(m3, type = "III")
tab_model(m3)
method.table.2 <- df.filtered %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_se")
names(method.table.2)[4] <- "web.frequency.mean"
method.table.2
# # Mean + std error of the mean
freq.method <- ggplot(method.table.2, aes(x=method, y=web.frequency.mean, color=method)) +
geom_errorbar(aes(ymin=web.frequency.mean-se, ymax=web.frequency.mean+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM web frequency by survey method") +
guides(color="none")
freq.method
# read students ranking
df.rank = read_csv('../data_mturk/emotion_top_2_word_survey_dueling_bandits_mturk.csv')
library(svglite)
library(tidyverse)
library(ggpubr)
library(rstatix)
library(sjPlot)
library(knitr)
library(equatiomatic)
# read students ranking
df.rank = read_csv('../data_mturk/emotion_top_2_word_survey_dueling_bandits_mturk.csv')
# read frequency in the web ranking
unigram.freq= read_csv('../data/unigram_freq.csv')
head(df.rank)
head(unigram.freq)
# merge datasets
df = merge(x = df.rank,
y = unigram.freq,
by.x="word",
by.y="word")
names(df)[7]  <- 'web.frequency'
head(df)
## check outliers
outliers <- df %>% identify_outliers(web.frequency)
outliers # funny, well
ggqqplot(df2, x = "web.frequency")
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks_mturk/lmer_mean_diff_survey_dueling_bandits_mturk.r", echo=TRUE)
df2 %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_se")
df %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_se")
df %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_se")
# read students ranking
df.rank = read_csv('../data_mturk/emotion_top_2_word_survey_dueling_bandits_mturk.csv')
# read frequency in the web ranking
unigram.freq= read_csv('../data/unigram_freq.csv')
head(df.rank)
head(unigram.freq)
# merge datasets
df = merge(x = df.rank,
y = unigram.freq,
by.x="word",
by.y="word")
names(df)[7]  <- 'web.frequency'
head(df)
df %>%
group_by(method) %>%
get_summary_stats(web.frequency, type = "mean_se")
# grouped boxplot
boxplot <- ggplot(df2, aes(x = method, y = web.frequency, color=method)) +
geom_boxplot() +
geom_point() +
guides(color="none")
# grouped boxplot
boxplot <- ggplot(df, aes(x = method, y = web.frequency, color=method)) +
geom_boxplot() +
geom_point() +
guides(color="none")
boxplot
boxplot
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/lmer_mean_diff_survey_dueling_bandits.r", echo=TRUE)
library(svglite)
library(tidyverse)
library(ggpubr)
library(rstatix)
library(sjPlot)
library(knitr)
library(equatiomatic)
# read students ranking
df.rank = read_csv('../data_mturk/emotion_top_2_word_survey_dueling_bandits_mturk.csv')
# read frequency in the web ranking
unigram.freq= read_csv('../data/unigram_freq.csv')
head(df.rank)
head(unigram.freq)
# merge datasets
df = merge(x = df.rank,
y = unigram.freq,
by.x="word",
by.y="word")
names(df)[7]  <- 'web.frequency'
head(df)
## check outliers
outliers <- df %>% identify_outliers(web.frequency)
outliers # funny, well
# filter out extreme outliers
df2 <- subset(df, photoID != 15 & photoID != 13 & photoID != 20)
## Check normality assumption
df2 %>% shapiro_test(web.frequency)
ggqqplot(df2, x = "web.frequency")
