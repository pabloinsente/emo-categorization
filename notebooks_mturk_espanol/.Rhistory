sex.ethnicity.sum.table
# Mean + std error of the mean
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point()
# Mean + std error of the mean
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point()
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex and ethnicity ")
# Mean + Standard error of the mean
ggplot(condition.sum.table, aes(y=sentimentScore, x=condition, colour=condition)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by survey language")
# Mean + Standard error of the mean
ggplot(condition.sum.table, aes(y=sentimentScore, x=condition, colour=condition)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by survey language")
s <- svgstring(width = 7,
height = 5)
ggplot(condition.sum.table, aes(y=sentimentScore, x=condition, colour=condition)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by survey language")
chart <- s()
cat(chart , file = "lmer_output/language_effect_free_mturk_espanol.txt")
cat(chart , file = "../../emotions_dashboard/data/language_effect_free_mturk_espanol.txt")
dev.off()
# Mean + std error of the mean
ggplot(sex.condition.sum.table, aes(x=condition, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by survey language and sex")
s <- svgstring(width = 7,
height = 5)
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by survey language and sex")
chart <- s()
cat(chart , file = "lmer_output/sex_language_effect_free_mturk_espanol.txt")
cat(chart , file = "../../emotions_dashboard/data/sex_language_effect_free_mturk_espanol.txt")
dev.off()
# Mean + std error of the mean
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex and ethnicity ")
s <- svgstring(width = 7,
height = 5)
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex and ethnicity ")
chart <- s()
cat(chart , file = "lmer_output/sex_et_effect_free_mturk_espanol.txt")
cat(chart , file = "../../emotions_dashboard/data/sex_et_effect_free_mturk_espanol.txt")
dev.off()
library(tidyverse)
df.free = read_csv("../clean_data_mturk_espanol/free_labeling_emotion_mturk_long_format_lmer_espanol.csv")
df.forced = read_csv("../clean_data_mturk_espanol/forced_choice_emotion_mturk_long_format_lmer_espanol.csv")
## match spelling
df.forced$emotion <- tolower(df.forced$emotion)
## remove uncertain as it means "I don't know"
df.free <- subset(df.free, label!="uncertain")
df.free <- subset(df.free, emotion!="uncertain")
df.forced <- subset(df.forced, label!="uncertain")
df.forced <- subset(df.forced, emotion!="uncertain")
table(df.forced$emotion)
table(df.forced$label)
df.forced
table(df.forced$emotion)
table(df.forced$label)
df.forced
df.free = read_csv("../clean_data_mturk_espanol/free_labeling_emotion_mturk_long_format_lmer_espanol.csv")
df.forced = read_csv("../clean_data_mturk_espanol/forced_choice_emotion_mturk_long_format_lmer_espanol.csv")
df.forced$label <- mapvalues(df.forced$label,
from=c("enfado", "felicidad", "asco", "tristeza", "miedo", "sorpresa", "incertidumbre"),
to=c("anger", "happiness", "disgust", 'sadness', 'fear', 'surprise', 'uncertain'))
library(plyr)
df.forced$label <- plyr::mapvalues(df.forced$label,
from=c("enfado", "felicidad", "asco", "tristeza", "miedo", "sorpresa", "incertidumbre"),
to=c("anger", "happiness", "disgust", 'sadness', 'fear', 'surprise', 'uncertain'))
## match spelling
df.forced$emotion <- tolower(df.forced$emotion)
## remove uncertain as it means "I don't know"
df.free <- subset(df.free, label!="uncertain")
df.free <- subset(df.free, emotion!="uncertain")
df.forced <- subset(df.forced, label!="uncertain")
df.forced <- subset(df.forced, emotion!="uncertain")
table(df.forced$emotion)
table(df.forced$label)
## add target
df.forced$correct <- ifelse(df.forced$emotion == df.forced$label, 1, 0)
## add between subjects predictor
df.forced$condition <- "forced"
df.forced$condition.dummy <- 0
df.forced$condition.center <- -.5
head(df.forced)
dim(table(df.free$emotion)) # 1081
table(df.free$label)
df.free$label <- plyr::mapvalues(df.free$label,
from=c("enfado", "felicidad", "asco", "tristeza", "miedo", "sorpresa", "incertidumbre"),
to=c("anger", "happiness", "disgust", 'sadness', 'fear', 'surprise', 'uncertain'))
dim(table(df.free$emotion)) # 1081
table(df.free$label)
library(tidyverse)
library(plyr)
df.free = read_csv("../clean_data_mturk_espanol/free_labeling_emotion_mturk_long_format_lmer_espanol.csv")
df.forced = read_csv("../clean_data_mturk_espanol/forced_choice_emotion_mturk_long_format_lmer_espanol.csv")
df.forced$label <- plyr::mapvalues(df.forced$label,
from=c("enfado", "felicidad", "asco", "tristeza", "miedo", "sorpresa", "incertidumbre"),
to=c("anger", "happiness", "disgust", 'sadness', 'fear', 'surprise', 'uncertain'))
df.free$label <- plyr::mapvalues(df.free$label,
from=c("enfado", "felicidad", "asco", "tristeza", "miedo", "sorpresa", "incertidumbre"),
to=c("anger", "happiness", "disgust", 'sadness', 'fear', 'surprise', 'uncertain'))
## match spelling
df.forced$emotion <- tolower(df.forced$emotion)
## remove uncertain as it means "I don't know"
df.free <- subset(df.free, label!="uncertain")
df.free <- subset(df.free, emotion!="uncertain")
df.forced <- subset(df.forced, label!="uncertain")
df.forced <- subset(df.forced, emotion!="uncertain")
table(df.forced$emotion)
table(df.forced$label)
## add target
df.forced$correct <- ifelse(df.forced$emotion == df.forced$label, 1, 0)
## add between subjects predictor
df.forced$condition <- "forced"
df.forced$condition.dummy <- 0
df.forced$condition.center <- -.5
head(df.forced)
dim(table(df.free$emotion)) # 1081
table(df.free$label)
head(df.free)
## add target
df.free$correct <- ifelse(df.free$emotion == df.free$label, 1, 0)
## add between subjects predictor
df.free$condition <- "free"
df.free$condition.dummy <- 1
df.free$condition.center <- .5
head(df.free)
mean(df.forced$correct)
mean(df.free$correct)
df.free$participantId <- df.free$participantId + 100
dim(table(df.forced$photoId)) # 168
dim(table(df.free$photoId))  # 670
df.forced$photoId <- gsub("\\..*","",df.forced$photoId)
df.free$photoId <- gsub("\\..*","", df.free$photoId)
dim(table(df.forced$photoId)) # 168
dim(table(df.free$photoId))  # 168
df <- rbind(df.forced, df.free)
# random variables as factors
df$participantIdF <- as.factor(df$participantId)
df$photoIdF <- as.factor(df$photoId)
library(lme4)
## dummy coded predictor
m1 <- glmer(correct ~ 1 + condition.dummy + (1 | participantIdF) +  (1 | photoIdF),
data = df,
family = binomial)
summary(m1)
fix.effect = -2.45
## odd ratio
exp(fix.effect) # 0.081
## probability
plogis(fix.effect) # 0.074
## probability
plogis(fix.effect) # 0.079
## centered  predictor
m2 <- glmer(correct ~ 1 + condition.center + (1 | participantIdF)  + (1 | photoIdF),
data = df,
family = binomial)
summary(m2)
###################
# plots of effects
###################
library(sjPlot)
library(sjlabelled)
library(sjmisc)
library(ggplot2)
plot_model(m1)
plot_model(m1, vline.color = "red")
plot_model(m1, transform = "plogis", show.values = TRUE, value.offset = .3)
plot_model(m1, show.values = TRUE, value.offset = .3)
plot_model(m1, type = "pred", terms = "condition.dummy")
plot_model(m1, type = "emm", terms = "condition.dummy")
tab_model(m1)
tab_model(m2)
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- plyr::rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
## Norms the data within specified groups in a data frame; it normalizes each
## subject (identified by idvar) so that they have the same mean, within each group
## specified by betweenvars.
##   data: a data frame.
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   na.rm: a boolean that indicates whether to ignore NA's
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
na.rm=FALSE, .drop=TRUE) {
library(plyr)
# Measure var on left, idvar + between vars on right of formula.
data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
.fun = function(xx, col, na.rm) {
c(subjMean = mean(xx[,col], na.rm=na.rm))
},
measurevar,
na.rm
)
# Put the subject means with original data
data <- merge(data, data.subjMean)
# Get the normalized data in a new column
measureNormedVar <- paste(measurevar, "_norm", sep="")
data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
mean(data[,measurevar], na.rm=na.rm)
# Remove this subject mean column
data$subjMean <- NULL
return(data)
}
## Gives count, un-normed mean, normed mean (with same between-group mean),
##   standard deviation, standard error of the mean, and confidence interval.
## If there are within-subject variables, calculate adjusted values using method from Morey (2008).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   withinvars: a vector containing names of columns that are within-subjects variables
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
# Ensure that the betweenvars and withinvars are factors
factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
FUN=is.factor, FUN.VALUE=logical(1))
if (!all(factorvars)) {
nonfactorvars <- names(factorvars)[!factorvars]
message("Automatically converting the following non-factors to factors: ",
paste(nonfactorvars, collapse = ", "))
data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
}
# Get the means from the un-normed data
datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Drop all the unused columns (these will be calculated with normed data)
datac$sd <- NULL
datac$se <- NULL
datac$ci <- NULL
# Norm each subject's data
ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
# This is the name of the new column
measurevar_n <- paste(measurevar, "_norm", sep="")
# Collapse the normed data - now we can treat between and within vars the same
ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Apply correction from Morey (2008) to the standard error and confidence interval
#  Get the product of the number of conditions of within-S variables
nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
FUN.VALUE=numeric(1)))
correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
# Apply the correction factor
ndatac$sd <- ndatac$sd * correctionFactor
ndatac$se <- ndatac$se * correctionFactor
ndatac$ci <- ndatac$ci * correctionFactor
# Combine the un-normed means with the normed results
merge(datac, ndatac)
}
correct.survey <- summarySE(df, measurevar="correct", groupvars=c("condition"))
correct.survey.plot <- ggplot(correct.survey, aes(x=condition, y=correct)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=correct-se, ymax=correct+se),
width=.2,                    # Width of the error bars
position=position_dodge(.9))
correct.survey.plot
correct.label <- summarySE(df, measurevar="correct", groupvars=c("label"))
correct.label
correct.label.plot <- ggplot(correct.label, aes(x = reorder(label, -correct), y=correct)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=correct-se, ymax=correct+se),
width=.2,                    # Width of the error bars
position=position_dodge(.9)) +
labs(x = "expected emotion label")
correct.label.plot
correct.survey.label <-  summarySEwithin(df, measurevar="correct",
betweenvars="condition",
withinvars=c("label"),
idvar="participantId")
correct.survey.label.plot <- ggplot(correct.survey.label, aes(x = reorder(label, -correct), y=correct, fill=condition)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=correct-se, ymax=correct+se),
width=.2,                    # Width of the error bars
position=position_dodge(.9)) +
labs(x = "expected emotion label")
correct.survey.label.plot
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks_mturk_espanol/lmer_pooled_free_forced_mturk_espanol.r", echo=TRUE)
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks_mturk_espanol/lmer_pooled_free_forced_mturk_espanol.r", echo=TRUE)
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks_mturk_espanol/lmer_refactored_r_free_responses_mturk_espanol.r", echo=TRUE)
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks_mturk/lmer_refactored_r_free_responses_mturk.r", echo=TRUE)
gc()
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/lmer_refactored_r_free_responses.r", echo=TRUE)
s <- svgstring()
p = ggplot(df,aes(sex,sentimentScore,color=ethnicity,group=ethnicity))+
geom_point()+
geom_smooth(method="lm",se=F)+
facet_wrap(~participantId)+
theme_bw()+
scale_color_manual(values=c("#1f77b4", "#ff7f0e"))
+ theme_apa()
p
svg.string.plot <- s()
cat(svg.string.plot, file = "lmer_output/participants_charts_lmer_free_uw_students.txt")
cat(svg.string.plot, file = "../../emotions_dashboard/data/participants_charts_lmer_free_uw_students.txt")
dev.off()
s <- svgstring()
p = ggplot(df,aes(sex,sentimentScore,color=ethnicity,group=ethnicity))+
geom_point()+
geom_smooth(method="lm",se=F)+
facet_wrap(~participantId)+
theme_bw()+
scale_color_manual(values=c("#1f77b4", "#ff7f0e")) + theme_apa()
p
svg.string.plot <- s()
cat(svg.string.plot, file = "lmer_output/participants_charts_lmer_free_uw_students.txt")
cat(svg.string.plot, file = "../../emotions_dashboard/data/participants_charts_lmer_free_uw_students.txt")
dev.off()
#####################################
#####################################
# Check homogeneity of variance
#####################################
#####################################
# https://ademos.people.uic.edu/Chapter18.html
# ANOVA of the between subjects residuals.
# the assumption is that the variance is not going to differ, we would hope to see
# NO STATISTICAL DIFFERENCES in the following procedure (i.e. p>0.05)
df$Model.F.Res<- residuals(m2) #extracts the residuals and places them in a new column in our original data table
df$Abs.Model.F.Res <-abs(df$Model.F.Res) #creates a new column with the absolute value of the residuals
df$Model.F.Res2 <- df$Abs.Model.F.Res^2 #squares the absolute values of the residuals to provide the more robust estimate
Levene.Model.F <- lm(Model.F.Res2 ~ participantId, data=df) #ANOVA of the squared residuals
anova(Levene.Model.F) #displays the results
format(4.440288e-07, scientific = F)
# save to html table
aov.btw.res <- kable(anova(Levene.Model.F), digits = 3, format = "html", caption = "ANOVA table for between subjects residuals")
cat(aov.btw.res, file = "lmer_output/anova_bwt_res_summary_free_uw_students.html")
cat(aov.btw.res, file = "../../emotions_dashboard/data/anova_bwt_res_summary_free_uw_students.html")
# Since the p value < 0.05, we can say that the variance of the residuals is equal and
# therefore the assumption of **homoscedasticity** NOT is met
s <- svgstring(width = 7,
height = 5)
Plot.Model.F <- plot(m2) #creates a fitted vs residual plot
Plot.Model.F
Plot.Model.F <- s()
cat(Plot.Model.F , file = "lmer_output/fitted_vs_residual_plot_free_uw_students.txt")
cat(Plot.Model.F , file = "../../emotions_dashboard/data/fitted_vs_residual_plot_free_uw_students.txt")
dev.off()
s <- svgstring(width = 7,
height = 5)
ggplot(data = resid1, aes(x = participantId, y = .std.ls.resid)) +
geom_point(alpha = 0.2) +
geom_smooth(method = "loess", se = FALSE) +
labs(y = "Least-Squares level-1 residuals",
title = "Least-Squares residuals by participant ID") + theme_apa()
l1.res <- s()
cat(l1.res , file = "lmer_output/l1_res_plot_free_uw_students.txt")
cat(l1.res , file = "../../emotions_dashboard/data/l1_res_plot_free_uw_students.txt")
dev.off()
s <- svgstring(width = 7,
height = 5)
ggplot(data = resid2, aes(x = participantId, y = .std.ranef.intercept)) +
geom_point(alpha = 0.4) +
geom_smooth(method = "loess", se = FALSE) +
labs(y = "Random effects - intercept",
title = "Intercept random effects against participant ID") + theme_apa()
l2.res.int <- s()
cat(l2.res.int , file = "lmer_output/l2_int_res_plot_free_uw_students.txt")
cat(l2.res.int , file = "../../emotions_dashboard/data/l2_int_res_plot_free_uw_students.txt")
dev.off()
require("lattice")
s <- svgstring(width = 7,
height = 5)
qqmath(m2, id=0.05) #id: identifies values that may be exerting undue influence on the model (i.e. outliers)
svg.qqplot <- s()
cat(svg.qqplot, file = "lmer_output/qqplot_lmer_free_uw_students.txt")
cat(svg.qqplot, file = "../../emotions_dashboard/data/qqplot_lmer_free_uw_students.txt")
dev.off()
CutOff = 4/nrow(infl)
print(CutOff)
s <- svgstring(width = 7,
height = 5)
# dotplot_diag(infl$cooksd, name = "cooks.distance", cutoff = "internal")
dotplot_diag(infl$cooksd, name = "cooks.distance", cutoff = CutOff) + theme_apa()
svg.string.plot <- s()
cat(svg.string.plot, file = "lmer_output/influence_datapoints_lmer_free_uw_students.txt")
cat(svg.string.plot, file = "../../emotions_dashboard/data/influence_datapoints_lmer_free_uw_students.txt")
dev.off()
high_cooksd = infl[infl$cooksd > CutOff, ] %>%
arrange(desc(cooksd))
head(high_cooksd, n=10)
#### high influence data points
high_cooksd$id
# IQR = as.numeric(format(IQR(infl$cooksd)*3, scientific = F))
CutOff = 4/nrow(infl)
print(CutOff)
s <- svgstring(width = 7,
height = 5)
# IQR = as.numeric(format(IQR(infl$cooksd)*3, scientific = F))
CutOff = 4/nrow(infl)
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/lmer_refactored_r_free_responses.r", echo=TRUE)
# Mean + std error of the mean
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex and ethnicity ") + theme_apa()
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
sex.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex"),  idvar="participantId")
sex.sum.table
ethnicity.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("ethnicity"), idvar="participantId")
ethnicity.sum.table
sex.ethnicity.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex","ethnicity"), idvar="participantId")
sex.ethnicity.sum.table
# Mean + Standard error of the mean
ggplot(sex.sum.table, aes(y=sentimentScore, x=sex, colour=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex") + theme_apa()
s <- svgstring(width = 7,
height = 5)
ggplot(sex.sum.table, aes(y=sentimentScore, x=sex, colour=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex") + theme_apa()
chart <- s()
cat(chart , file = "lmer_output/sex_effect_free.txt")
cat(chart , file = "../../emotions_dashboard/data/sex_effect_free.txt")
dev.off()
# Mean + Standard error of the mean
ggplot(ethnicity.sum.table, aes(y=sentimentScore, x=ethnicity, colour=ethnicity)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by ethnicity") + theme_apa()
s <- svgstring(width = 7,
height = 5)
ggplot(ethnicity.sum.table, aes(y=sentimentScore, x=ethnicity, colour=ethnicity)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by ethnicity") + theme_apa()
chart <- s()
cat(chart , file = "lmer_output/ethnicity_effect_free.txt")
cat(chart , file = "../../emotions_dashboard/data/ethnicity_effect_free.txt")
dev.off()
# Mean + std error of the mean
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex and ethnicity ") + theme_apa()
s <- svgstring(width = 7,
height = 5)
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex and ethnicity ") + theme_apa()
chart <- s()
cat(chart , file = "lmer_output/sex_et_effect_free.txt")
cat(chart , file = "../../emotions_dashboard/data/sex_et_effect_free.txt")
dev.off()
nrow(df.filtered)
library(tidyverse)
library(svglite)
library(equatiomatic)
library(ggforce)
library(papaja)
library(rstatix)
library(rjson)
df.free = read_csv("../clean_data_mturk_espanol/free_labeling_emotion_mturk_long_format_lmer_espanol.csv")
df.forced = read_csv("../clean_data_mturk_espanol/forced_choice_emotion_mturk_long_format_lmer_espanol.csv")
df.free
