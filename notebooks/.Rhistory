by = list(df$sex),                    # Specify group indicator
FUN = mean)                           # Specify function (i.e. mean)
aggregate(x = df$sentimentScore,                # Specify data column
by = list(df$ethnicity),              # Specify group indicator
FUN = mean)                           # Specify function (i.e. mean)
ord_m1 <- clmm2(
emotionF ~ 1 + sexC*ethnicityC + (1 + sexC*ethnicityC|participantId),
data=df,
Hess = TRUE)
ord_m1 <- clmm2(
emotionF ~ 1 + sexC*ethnicityC + (1 + sexC*ethnicityC|participantId),
data=df,
Hess = TRUE)
# to get random effects correctly
ord_m2 <- clmm(
emotionF ~ 1 + sexC*ethnicityC + (1 + sexC*ethnicityC|participantId),
data=df,
Hess = TRUE)
# for nominal test
ord_m3 <- clm(
emotionF ~ sexC*ethnicityC + (sexC*ethnicityC|participantId),
data=df,
Hess = TRUE)
# for nominal test
ord_m3 <- clm(
emotionF ~ sexC*ethnicityC + (sexC*ethnicityC|participantId),
data=df,
Hess = TRUE)
#######
# summary significant results
summary(ord_m1)
summary(ord_m2)
summary(ord_m3)
######
## sex
logit = coef(ord_m2)[8]
exp(logit) # odds ratio
plogis(logit) # probbility
logit = coef(ord_m2)[9]
exp(logit) # odds ratio
plogis(logit) # probability
logit = coef(ord_m2)[10]
exp(logit) # odds ratio
plogis(logit) # probability
#######
# Multicolinearity
library(stats)
chisq.test(df$sexF, df$ethnicityF, correct=FALSE)
nominal_test(ord_m3)
library(equatiomatic)
formula_lmer <- extract_eq(ord_m3)
cat(formula_lmer, file = "lmer_output/formula_ord_lmer_summary_forced.txt")
cat(formula_lmer, file = "../../emotions_dashboard/data/formula_ord_lmer_summary_forced.txt")
library(sjPlot)
tab_model(ord_m2, file = "lmer_output/ord_lmer_summary_forced.html")
tab_model(ord_m2, file = "../../emotions_dashboard/data/ord_lmer_summary_forced.html")
sjt.xtab(df$sexF,
df$ethnicityF,
var.labels = c("Sex", "Ethnicity"),
show.exp = TRUE,
emph.total = TRUE,
file = "lmer_output/chi_sex_et_forced.html")
sjt.xtab(df$sexF,
df$ethnicityF,
var.labels = c("Sex", "Ethnicity"),
show.exp = TRUE,
emph.total = TRUE,
file = "../../emotions_dashboard/data/chi_sex_et_forced.html")
library(broom)
library(htmlTable)
nominal.test.table <- nominal_test(ord_m3) %>%
tidy() %>%
drop_na() %>%
addHtmlTableStyle(align = "r") %>%
txtRound(digits = 3) %>%
htmlTable()
nominal.test.table
cat(nominal.test.table, file = "lmer_output/nominal_test_forced.html")
cat(nominal.test.table, file = "../../emotions_dashboard/data/nominal_test_forced.html")
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/ordinal_lmer_forced_responses.r", echo=TRUE)
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/ordinal_lmer_forced_responses - Copy.r", echo=TRUE)
two_way_sex_ethnicity
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/ordinal_lmer_forced_responses - Copy.r", echo=TRUE)
library(tidyverse)
library(ordinal)
library("RColorBrewer")
df_students = read_csv("../clean_data/forced_choice_emotion_uw_students_long_format_lmer.csv")
table(df_students$emotion)
# drop "Other" to break tie with "Neutral" and keep ordinal variable
df <- subset(df_students, emotion!="Other")
# drop because = to "I don't know what the person in the picture is feeling" Not "The person is feeling uncertainty"
df <- subset(df_mturk, emotion!="Uncertain")
table(df$emotion)
# drop "Other" to break tie with "Neutral" and keep ordinal variable
df <- subset(df_students, emotion!="Other")
# drop because = to "I don't know what the person in the picture is feeling" Not "The person is feeling uncertainty"
df <- subset(df_students, emotion!="Uncertain")
table(df$emotion)
df_students = read_csv("../clean_data/forced_choice_emotion_uw_students_long_format_lmer.csv")
table(df_students$emotion)
# drop "Other" to break tie with "Neutral" and keep ordinal variable
df <- subset(df_students, emotion!="Other")
# drop because = to "I don't know what the person in the picture is feeling" Not "The person is feeling uncertainty"
df <- subset(df_students, emotion!="Uncertain")
table(df$emotion)
# drop "Other" to break tie with "Neutral" and keep ordinal variable
df <- subset(df_students, emotion!="Other")
table(df$emotion)
# drop because = to "I don't know what the person in the picture is feeling" Not "The person is feeling uncertainty"
df <- subset(df_students, emotion!="Uncertain")
table(df$emotion)
df_students = read_csv("../clean_data/forced_choice_emotion_uw_students_long_format_lmer.csv")
table(df_students$emotion)
# drop "Other" to break tie with "Neutral" and keep ordinal variable
df <- subset(df_students, emotion!="Other")
# drop because = to "I don't know what the person in the picture is feeling" Not "The person is feeling uncertainty"
df <- subset(df_students, emotion!="Uncertain")
# drop "Other" to break tie with "Neutral" and keep ordinal variable
df <- subset(df_students, emotion!="Other")
# drop because = to "I don't know what the person in the picture is feeling" Not "The person is feeling uncertainty"
df <- subset(df, emotion!="Uncertain")
table(df$emotion)
df$emotionF <- factor(df$emotion,
order = TRUE,
levels =c('Disgust', 'Anger', 'Fear', 'Sadness', 'Neutral', 'Surprise', 'Happiness'))
df$participantIdF <- as.factor(df$participantId)
df$ethnicityF <- as.factor(df$ethnicity)
df$sexF <- as.factor(df$sex)
table(df$participantIdF)
table(df$ethnicityF)
table(df$sexF)
str(df)
df <- na.omit(df)
dim(df)
#####################################
#####################################
library(svglite)
RdBu8Alter <- c("#B2182B", "#D6604D", "#F7F7F7", "#D1E5F0", "#92C5DE", "#4393C3", "#2166AC", "#053061")
two_way_sex_ethnicity <- df %>%
mutate(emotionF = ordered(emotionF, levels=rev(levels(emotionF)))) %>%
ggplot( aes(x = sexF, fill = emotionF)) +
geom_bar(position = "fill") +
facet_grid(. ~ethnicityF) +
labs(y = "proportion", x = "sex", fill ="emotion") +
scale_fill_manual(values = RdBu8Alter) +
theme_minimal()
two_way_sex_ethnicity
s <- svgstring(width = 7,
height = 5)
two_way_sex_ethnicity
chart <- s()
cat(chart , file = "lmer_output/sex_ethnicity_forced.txt")
cat(chart , file = "../../emotions_dashboard/data/sex_ethnicity_forced.txt")
dev.off()
sex_chart <- df %>%
mutate(emotionF = ordered(emotionF, levels=rev(levels(emotionF)))) %>%
ggplot( aes(x = sexF, fill = emotionF)) +
geom_bar(position = "fill") +
labs(y = "proportion", x = "sex", fill ="emotion") +
scale_fill_manual(values = RdBu8Alter) +
theme_minimal()
sex_chart
s <- svgstring(width = 7,
height = 5)
sex_chart
chart <- s()
cat(chart , file = "lmer_output/sex_forced.txt")
cat(chart , file = "../../emotions_dashboard/data/sex_forced.txt")
dev.off()
et_chart <- df %>%
mutate(emotionF = ordered(emotionF, levels=rev(levels(emotionF)))) %>%
ggplot( aes(x = ethnicityF, fill = emotionF)) +
geom_bar(position = "fill") +
labs(y = "proportion", x = "ethnicity", fill ="emotion") +
scale_fill_manual(values = RdBu8Alter) +
theme_minimal()
et_chart
s <- svgstring(width = 7,
height = 5)
et_chart
chart <- s()
cat(chart , file = "lmer_output/ethnicity_forced.txt")
cat(chart , file = "../../emotions_dashboard/data/ethnicity_forced.txt")
dev.off()
aggregate(x = df$sentimentScore,                # Specify data column
by = list(df$sex),                    # Specify group indicator
FUN = mean)                           # Specify function (i.e. mean)
aggregate(x = df$sentimentScore,                # Specify data column
by = list(df$ethnicity),              # Specify group indicator
FUN = mean)                           # Specify function (i.e. mean)
ord_m1 <- clmm2(
emotionF ~ 1 + sexC*ethnicityC + (1 + sexC*ethnicityC|participantId),
data=df,
Hess = TRUE)
# to get random effects correctly
ord_m2 <- clmm(
emotionF ~ 1 + sexC*ethnicityC + (1 + sexC*ethnicityC|participantId),
data=df,
Hess = TRUE)
# for nominal test
ord_m3 <- clm(
emotionF ~ sexC*ethnicityC + (sexC*ethnicityC|participantId),
data=df,
Hess = TRUE)
#######
# summary significant results
summary(ord_m1)
summary(ord_m2)
######
## sex
logit = coef(ord_m2)[8]
exp(logit) # odds ratio
plogis(logit) # probbility
######
## sex
logit = coef(ord_m2)[7]
exp(logit) # odds ratio
plogis(logit) # probbility
logit = coef(ord_m2)[8]
exp(logit) # odds ratio
plogis(logit) # probability
logit = coef(ord_m2)[9]
exp(logit) # odds ratio
plogis(logit) # probability
#######
# Multicolinearity
library(stats)
chisq.test(df$sexF, df$ethnicityF, correct=FALSE)
nominal_test(ord_m3)
library(equatiomatic)
formula_lmer <- extract_eq(ord_m3)
cat(formula_lmer, file = "lmer_output/formula_ord_lmer_summary_forced.txt")
cat(formula_lmer, file = "../../emotions_dashboard/data/formula_ord_lmer_summary_forced.txt")
library(sjPlot)
tab_model(ord_m2, file = "lmer_output/ord_lmer_summary_forced.html")
tab_model(ord_m2, file = "../../emotions_dashboard/data/ord_lmer_summary_forced.html")
sjt.xtab(df$sexF,
df$ethnicityF,
var.labels = c("Sex", "Ethnicity"),
show.exp = TRUE,
emph.total = TRUE,
file = "lmer_output/chi_sex_et_forced.html")
sjt.xtab(df$sexF,
df$ethnicityF,
var.labels = c("Sex", "Ethnicity"),
show.exp = TRUE,
emph.total = TRUE,
file = "../../emotions_dashboard/data/chi_sex_et_forced.html")
library(broom)
library(htmlTable)
nominal.test.table <- nominal_test(ord_m3) %>%
tidy() %>%
drop_na() %>%
addHtmlTableStyle(align = "r") %>%
txtRound(digits = 3) %>%
htmlTable()
nominal.test.table
cat(nominal.test.table, file = "lmer_output/nominal_test_forced.html")
cat(nominal.test.table, file = "../../emotions_dashboard/data/nominal_test_forced.html")
library(lme4)
library(car)
library(lmerTest)
library(tidyverse)
library(ragg)
library(HLMdiag)
library(VCA)
library(hrbrthemes)
library(ggResidpanel)
library(sjPlot)
library(webshot)
library(equatiomatic)
library(svglite)
library(knitr)
library(lme4)
library(car)
library(lmerTest)
library(tidyverse)
library(ragg)
library(HLMdiag)
library(VCA)
library(hrbrthemes)
library(ggResidpanel)
library(sjPlot)
library(webshot)
library(equatiomatic)
library(svglite)
library(knitr)
df <- read_csv("../clean_data/free_labeling_emotion_uw_students_long_format_lmer.csv")
table(df$emotion)
source("//wsl$/Ubuntu-20.04/home/pablo_ubuntu/emo-categorization/notebooks/lmer_refactored_r_free_responses.r", echo=TRUE)
# head(high_leverage, n=10)
high_leverage_participants
high_cooksd_participants$participantId
high_leverage$id
summary(m3)
aov.m3
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
# Ensure that the betweenvars and withinvars are factors
factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
FUN=is.factor, FUN.VALUE=logical(1))
if (!all(factorvars)) {
nonfactorvars <- names(factorvars)[!factorvars]
message("Automatically converting the following non-factors to factors: ",
paste(nonfactorvars, collapse = ", "))
data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
}
# Get the means from the un-normed data
datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Drop all the unused columns (these will be calculated with normed data)
datac$sd <- NULL
datac$se <- NULL
datac$ci <- NULL
# Norm each subject's data
ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
# This is the name of the new column
measurevar_n <- paste(measurevar, "_norm", sep="")
# Collapse the normed data - now we can treat between and within vars the same
ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Apply correction from Morey (2008) to the standard error and confidence interval
#  Get the product of the number of conditions of within-S variables
nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
FUN.VALUE=numeric(1)))
correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
# Apply the correction factor
ndatac$sd <- ndatac$sd * correctionFactor
ndatac$se <- ndatac$se * correctionFactor
ndatac$ci <- ndatac$ci * correctionFactor
# Combine the un-normed means with the normed results
merge(datac, ndatac)
}
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
na.rm=FALSE, .drop=TRUE) {
library(plyr)
# Measure var on left, idvar + between vars on right of formula.
data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
.fun = function(xx, col, na.rm) {
c(subjMean = mean(xx[,col], na.rm=na.rm))
},
measurevar,
na.rm
)
# Put the subject means with original data
data <- merge(data, data.subjMean)
# Get the normalized data in a new column
measureNormedVar <- paste(measurevar, "_norm", sep="")
data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
mean(data[,measurevar], na.rm=na.rm)
# Remove this subject mean column
data$subjMean <- NULL
return(data)
}
aov.m3
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
sex.sum.table <- summarySE(df.filtered, measurevar="sentimentScore", groupvars=c("sex"))
sex.sum.table
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
sex.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex"))
sex.sum.table
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
sex.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex"))
summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex"))
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
sex.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex"))
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
sex.sum.table <-
summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex"))
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
sex.sum.table <-
summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex"),  idvar="participantId")
sex.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex"), idvar="participantId")
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
na.rm=FALSE, .drop=TRUE) {
library(plyr)
# Measure var on left, idvar + between vars on right of formula.
data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
.fun = function(xx, col, na.rm) {
c(subjMean = mean(xx[,col], na.rm=na.rm))
},
measurevar,
na.rm
)
# Put the subject means with original data
data <- merge(data, data.subjMean)
# Get the normalized data in a new column
measureNormedVar <- paste(measurevar, "_norm", sep="")
data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
mean(data[,measurevar], na.rm=na.rm)
# Remove this subject mean column
data$subjMean <- NULL
return(data)
}
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
# Ensure that the betweenvars and withinvars are factors
factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
FUN=is.factor, FUN.VALUE=logical(1))
if (!all(factorvars)) {
nonfactorvars <- names(factorvars)[!factorvars]
message("Automatically converting the following non-factors to factors: ",
paste(nonfactorvars, collapse = ", "))
data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
}
# Get the means from the un-normed data
datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Drop all the unused columns (these will be calculated with normed data)
datac$sd <- NULL
datac$se <- NULL
datac$ci <- NULL
# Norm each subject's data
ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
# This is the name of the new column
measurevar_n <- paste(measurevar, "_norm", sep="")
# Collapse the normed data - now we can treat between and within vars the same
ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
# Apply correction from Morey (2008) to the standard error and confidence interval
#  Get the product of the number of conditions of within-S variables
nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
FUN.VALUE=numeric(1)))
correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
# Apply the correction factor
ndatac$sd <- ndatac$sd * correctionFactor
ndatac$se <- ndatac$se * correctionFactor
ndatac$ci <- ndatac$ci * correctionFactor
# Combine the un-normed means with the normed results
merge(datac, ndatac)
}
# summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
sex.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex"),  idvar="participantId")
sex.sum.table
ethnicity.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("ethnicity"), idvar="participantId")
ethnicity.sum.table
sex.ethnicity.sum.table <- summarySEwithin(df.filtered, measurevar="sentimentScore", withinvars=c("sex","ethnicity"), idvar="participantId")
sex.ethnicity.sum.table
# Mean + Standard error of the mean
ggplot(sex.sum.table, aes(y=sentimentScore, x=sex, colour=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex")
s <- svgstring(width = 7,
height = 5)
ggplot(sex.sum.table, aes(y=sentimentScore, x=sex, colour=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex")
chart <- s()
cat(chart , file = "lmer_output/sex_effect_free.txt")
cat(chart , file = "../../emotions_dashboard/data/sex_effect_free.txt")
dev.off()
# Mean + Standard error of the mean
ggplot(ethnicity.sum.table, aes(y=sentimentScore, x=ethnicity, colour=ethnicity)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by ethnicity")
s <- svgstring(width = 7,
height = 5)
ggplot(ethnicity.sum.table, aes(y=sentimentScore, x=ethnicity, colour=ethnicity)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by ethnicity")
chart <- s()
cat(chart , file = "lmer_output/ethnicity_effect_free.txt")
cat(chart , file = "../../emotions_dashboard/data/ethnicity_effect_free.txt")
dev.off()
# Mean + std error of the mean
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex and ethnicity ")
s <- svgstring(width = 7,
height = 5)
ggplot(sex.ethnicity.sum.table, aes(x=ethnicity, y=sentimentScore, fill=sex, color=sex)) +
geom_errorbar(aes(ymin=sentimentScore-se, ymax=sentimentScore+se), width=.1) +
geom_point() +
labs (title= "Mean and SEM sentiment score by sex and ethnicity ")
chart <- s()
cat(chart , file = "lmer_output/sex_et_effect_free.txt")
cat(chart , file = "../../emotions_dashboard/data/sex_et_effect_free.txt")
dev.off()
